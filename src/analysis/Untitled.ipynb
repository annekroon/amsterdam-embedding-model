{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,  TfidfTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import logging\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "import embeddingvectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import gensim\n",
    "import os\n",
    "\n",
    "\n",
    "#path_to_embeddings='/home/anne/tmpanne/AEM_small_sample/test'\n",
    "\n",
    "path_to_data='/home/anne/tmpanne/AEM_data/'\n",
    "dataset = 'dataset_vermeer.pkl'\n",
    "dataset = 'dataset_burscher.pkl'\n",
    "outputpath = '/home/anne/tmpanne/AEM_output/'\n",
    "path_to_embeddings = '/home/anne/tmpanne/fullsample/'\n",
    "\n",
    "class classifier_analyzer():\n",
    "    \n",
    "    def __init__(self, path_to_data, path_to_embeddings, dataset):\n",
    "        self.nmodel = 0\n",
    "        df = pd.read_pickle(path_to_data + dataset)\n",
    "        logging.info(\"... loading the data...\\n\\nthis is length of the dataframe: {}\".format(len(df)))\n",
    "        self.test_size = 0.2\n",
    "        self.data = df['text']\n",
    "        self.labels = df['topic']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.labels, test_size=self.test_size, random_state=42)\n",
    "        self.basepath = path_to_embeddings\n",
    "        self.names = [\"Passive Agressive\", \"SGDClassifier\" , \"SVM\", \"ET\"]\n",
    "        self.parameters = [\n",
    "\n",
    "                    {'clf__loss': ('hinge', 'squared_hinge'),\n",
    "                    'clf__C': (0.01, 0.5, 1.0)   ,\n",
    "                    'clf__fit_intercept': (True, False) ,\n",
    "                    #'vect__ngram_range': [(1, 1), (1, 2)] ,\n",
    "                #    'tfidf__use_idf' :(True ,False),\n",
    "                    'clf__max_iter': (5 ,10 ,15) } ,\n",
    "\n",
    "                    {'clf__max_iter': (20, 30) ,\n",
    "                    'clf__alpha': (1e-2, 1e-3, 1e-5),\n",
    "                    'clf__penalty': ('l2', 'elasticnet')} ,\n",
    "\n",
    "                    {'clf__C': [1, 10, 100, 1000],\n",
    "                    'clf__gamma': [0.001, 0.0001],\n",
    "                    'clf__kernel': ['rbf', 'linear']},\n",
    "\n",
    "\n",
    "                    { \"clf__max_features\": ['auto', 'sqrt', 'log2'] }\n",
    "\n",
    "                     ]\n",
    "        self.classifiers = [PassiveAggressiveClassifier(), \n",
    "                            SGDClassifier(),\n",
    "                            SVC(),\n",
    "                            ExtraTreesClassifier() ]\n",
    "      \n",
    "\n",
    "    def get_w2v_model(self):\n",
    "        '''yields a dict with one item. key is the filename, value the gensim model'''\n",
    "\n",
    "        filenames = [e for e in os.listdir(self.basepath) if not e.startswith('.')]\n",
    "\n",
    "        for fname in filenames:\n",
    "            model = {}\n",
    "            path = os.path.join(self.basepath, fname)\n",
    "            logging.info(\"\\nLoading gensim model\")\n",
    "\n",
    "            if fname.startswith('w2v'):\n",
    "                mod = gensim.models.Word2Vec.load(path)\n",
    "            else:\n",
    "                mod = gensim.models.KeyedVectors.load_word2vec_format(path)\n",
    "\n",
    "            model['gensimmodel'] = dict(zip(mod.wv.index2word, mod.wv.vectors))\n",
    "            model['filename'] = fname\n",
    "            self.nmodel +=1\n",
    "            logging.info(\"loaded gensim model nr {}, named: {}\".format(self.nmodel, model['filename']))\n",
    "            yield model\n",
    "\n",
    "\n",
    "    def get_vectorizer(self, vectorizer, model):\n",
    "        logging.info(\"the vectorizer is: {}\".format(vectorizer))\n",
    "        \n",
    "        vec = {}   \n",
    "        vec['filename'] = vectorizer\n",
    "        if vectorizer == 'w2v_count':\n",
    "            s = embeddingvectorizer.EmbeddingCountVectorizer(model['gensimmodel'], 'mean')\n",
    "        elif vectorizer == 'w2v_tfidf':\n",
    "            s = embeddingvectorizer.EmbeddingTfidfVectorizer(model['gensimmodel'], 'mean')\n",
    "        vec['vectorizer'] = s\n",
    "    \n",
    "        yield vec\n",
    "\n",
    "\n",
    "    def gridsearch_with_classifiers(self):\n",
    "        class_report = []\n",
    "        results = []\n",
    "        \n",
    "        for model in self.get_w2v_model():\n",
    "            for v in [\"w2v_count\", \"w2v_tfidf\"]:\n",
    "                for vec in self.get_vectorizer(v, model):\n",
    "                    print(\"loaded the vectorizer: {}\".format(vec['filename'])) \n",
    "                    for name, classifier, params in zip(self.names, self.classifiers, self.parameters):\n",
    "                        my_dict = {}\n",
    "                        \n",
    "                        logging.info(\"Starting gridsearch CV..\")\n",
    "                        logging.info(\"Classifier name: {}\\n\\n\\n\\n\\nModel name:{}\\n\\n\\n\\n\\nVectorizer: {}\\n\\n\\n\\n\\nParameter settings: {}\\n\".format(name, model['filename'], vec['filename'], params)) \n",
    "                        \n",
    "                        clf_pipe = Pipeline([ ('vect', vec['vectorizer']), ('clf', classifier), ])\n",
    "\n",
    "                        gs_clf = GridSearchCV(clf_pipe, param_grid=params, cv=2)\n",
    "                        clf = gs_clf.fit(self.X_train, self.y_train)\n",
    "                        score = clf.score(self.X_test, self.y_test)\n",
    "\n",
    "                        logging.info(\"{} score: {}\".format(name, score))\n",
    "                        #logging.info(\"{} are the best estimators\".format(clf.best_estimator_))\n",
    "\n",
    "                        results_to_dict = classification_report((clf.best_estimator_.predict(self.X_test)), self.y_test, output_dict= True)\n",
    "\n",
    "                        results_to_dict['classifier'] = name\n",
    "                        results_to_dict['parameters'] = clf.best_params_\n",
    "                        results_to_dict['vectorizer'] = vec['filename']\n",
    "                        results_to_dict['model'] = model['filename']\n",
    "\n",
    "                        logging.info(\"Created dictionary with classification report: \\n\\n{}\".format(results_to_dict))\n",
    "                        class_report.append(results_to_dict)\n",
    "                        \n",
    "                        y_hats = clf.predict(self.X_test)\n",
    "                        results.append({\"predicted\": y_hats,\n",
    "                                        \"actual\" : self.y_test.values  ,\n",
    "                                        \"classifier\": name} )\n",
    "                        \n",
    "        return class_report, results\n",
    "    \n",
    "    def gridsearch_with_classifiers_baseline(self):\n",
    "        class_report = []\n",
    "        results = []\n",
    "        \n",
    "        for vec, n in zip([CountVectorizer(), TfidfVectorizer()], [\"Count\", \"Tfidf\"]):\n",
    "            \n",
    "            print(\"loaded the vectorizer: {}\\n\\n\\{}\".format(n, vec)) \n",
    "            \n",
    "            for name, classifier, params in zip(self.names, self.classifiers, self.parameters):\n",
    "                my_dict = {}\n",
    "\n",
    "                logging.info(\"Starting gridsearch CV..\")\n",
    "                logging.info(\"Classifier name: {}\\n classifier:{}\\n params{}\\n\".format(name, classifier, params)) \n",
    "\n",
    "                clf_pipe = Pipeline([ ('vect', vec), ('clf', classifier), ])\n",
    "\n",
    "                gs_clf = GridSearchCV(clf_pipe, param_grid=params, cv=2)\n",
    "                clf = gs_clf.fit(self.X_train, self.y_train)\n",
    "                score = clf.score(self.X_test, self.y_test)\n",
    "\n",
    "                logging.info(\"{} score: {}\".format(name, score))\n",
    "                logging.info(\"{} are the best estimators\".format(clf.best_estimator_))\n",
    "\n",
    "                results_to_dict = classification_report((clf.best_estimator_.predict(self.X_test)), self.y_test, output_dict= True)\n",
    "\n",
    "                results_to_dict['classifier'] = name\n",
    "                results_to_dict['parameters'] = clf.best_params_\n",
    "                results_to_dict['vectorizer'] = n\n",
    "                results_to_dict['model'] = \"baseline\"\n",
    "                \n",
    "                logging.info(\"Created dictionary with classification report: \\n\\n{}\".format(results_to_dict))\n",
    "                class_report.append(results_to_dict)\n",
    "\n",
    "                y_hats = clf.predict(self.X_test)\n",
    "                results.append({\"predicted\": y_hats,\n",
    "                                \"actual\" : self.y_test.values  ,\n",
    "                                \"classifier\": name} )\n",
    "                \n",
    "        return class_report, results\n",
    "\n",
    "\n",
    "def clean_df_true_pred(results):\n",
    "    data = pd.DataFrame.from_dict(results)\n",
    "\n",
    "    predicted = data.predicted.apply(pd.Series).merge(data, right_index = True, left_index = True) \\\n",
    "    .drop([\"predicted\"], axis = 1).melt(id_vars = ['classifier'], value_name = \"Predicted label\")\n",
    "\n",
    "    actual = data.actual.apply(pd.Series).merge(data, right_index = True, left_index = True) \\\n",
    "    .drop([\"predicted\"], axis = 1).melt(id_vars = ['classifier'], value_name = \"Actual label\")\n",
    "\n",
    "    df = pd.merge(predicted, actual, how = 'inner', left_index = True, right_index = True)\n",
    "    df['Classifier'] = df['classifier_x']\n",
    "    df = df[df.variable_x != 'actual']\n",
    "    df = df[['Predicted label', 'Actual label', 'Classifier']]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "def get_scores(path_to_data, path_to_embeddings, dataset, outputpath):\n",
    "    a = classifier_analyzer(path_to_data=path_to_data, path_to_embeddings=path_to_embeddings, dataset=dataset)\n",
    "    class_report, results = a.gridsearch_with_classifiers()\n",
    "\n",
    "    fname_accuracy = '{}embeddings_classreport_{}.json'.format(outputpath, dataset)\n",
    "    fname_predictions = '{}embeddings_true_predicted_{}.json'.format(outputpath, dataset)\n",
    "\n",
    "    with open(fname_accuracy, mode = 'w') as fo:\n",
    "        json.dump(class_report, fo)\n",
    "        \n",
    "    df = clean_df_true_pred(results)\n",
    "    df.to_json(fname_predictions)\n",
    "\n",
    "\n",
    "def get_scores_baseline(path_to_data, path_to_embeddings, dataset, outputpath):\n",
    "    a = classifier_analyzer(path_to_data=path_to_data, path_to_embeddings=path_to_embeddings, dataset=dataset)\n",
    "    class_report, results = a.gridsearch_with_classifiers_baseline()\n",
    "\n",
    "    fname_accuracy = '{}baseline_classreport_{}.json'.format(outputpath, dataset)\n",
    "    fname_true_predicted = '{}baseline_true_predicted_{}.json'.format(outputpath, dataset)\n",
    "\n",
    "    with open(fname_accuracy, mode = 'w') as fo:\n",
    "        json.dump(class_report, fo)\n",
    "\n",
    "    df = clean_df_true_pred(results)\n",
    "    df.to_json(fname_true_predicted)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "    logging.root.setLevel(level=logging.INFO)\n",
    "    \n",
    "    get_scores(path_to_embeddings=path_to_embeddings,path_to_data=path_to_data, dataset=dataset, outputpath = outputpath)\n",
    "    get_scores_baseline(path_to_embeddings=path_to_embeddings,path_to_data=path_to_data, dataset=dataset, outputpath=outputpath)\n",
    "\n",
    "#\"w2v_count\", \"w2v_tfidf\", \"count\", \"tfidf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wereld, zondagmorg, antropolog, dr, mattijs, p...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>samenvattingd, speurtocht, efraim, zuroff, naz...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vol, verwacht, klopp, hartjes, onz, stoer, man...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nieuwkomer, bedrijf, denkt, flink, salaris, ge...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ziekenhuiz, hengelo, leeuward, vandag, gestaak...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ajacied, klaasjan, huntelar, gisterocht, vrien...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pol, gemeent, oswiecim, houdt, juli, referendu...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>politiek, lev, staatssecretaris, hof, vvd, zij...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brit, over, ieder, pasgebor, baby, kraampresen...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vermoed, zon, noordkoreaan, leider, kim, jongi...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kop, gonzalez, geeft, columbian, red, vreugdet...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>open, ministerie, stelt, strafrecht, onderzoek...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>koningin, beatrix, hoogsteig, person, hangt, b...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>amerikan, ministerie, defensie, gister, all, m...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rio, janeiro, noord, brazilie, boer, familie, ...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>busbedrijf, connexxion, koninginnedag, tijden,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>samenvattingdor, mariek, ess, delft, dinsdag, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hoofdrol, vertolk, nieuw, opera, international...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>war, haald, kabinet, inen, snel, 8, miljard, e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gestrand, bangkok, duikt, inen, sinterklas, aa...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>onz, correspondentwagen, maandagpopulair, maal...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mens, vloer, won, 19deeeuw, da, costabuurt, am...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>amsterdam, aantal, vrouw, tijden, kort, bevall...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>elsbeth, etty, volgend, wek, vakantie, column,...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kabinet, vannacht, akkoord, bereikt, begrot, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>samenvattingdor, manno, den, berg, herman, sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>zit, sind, twee, dag, wer, thuis, etag, amster...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>minister, grav, defensie, gister, eind, kamerd...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>highlightcd, tweedor, jan, colijndoetinchem, z...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nederland, spoorweg, gan, lon, inhoud, conduct...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12529</th>\n",
       "      <td>uitzendconcern, randstad, gat, komend, wek, tw...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12530</th>\n",
       "      <td>precies, period, abn, amro, eerst, ker, kwarta...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12531</th>\n",
       "      <td>rotterdam, 20, sept, nieuw, hooglerar, moet, l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12532</th>\n",
       "      <td>kroonprin, willemalexander, maxima, trouw, 2, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12533</th>\n",
       "      <td>samenvattingvan, onz, financiel, redactie, ams...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12534</th>\n",
       "      <td>redacteur, amsterdam, zender, at5, voel, pietj...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12535</th>\n",
       "      <td>secretarisgeneral, navo, georg, robertson, mac...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12536</th>\n",
       "      <td>amerikan, president, bush, elk, versoepel, eco...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12537</th>\n",
       "      <td>aardedonker, onderan, keldertrap, kijk, angsti...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12538</th>\n",
       "      <td>samenvattingdor, bert, huisjes, amsterdam, don...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12539</th>\n",
       "      <td>verenigd, stat, geconfronteerd, ernstigst, ene...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12540</th>\n",
       "      <td>genetisch, gemanipuleerd, maissoort, starlink,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12541</th>\n",
       "      <td>kop, asielzoeker, verwijdercentrum, duik, vak,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12542</th>\n",
       "      <td>wit, kist, bedekt, wit, bloem, kaart, emotione...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12543</th>\n",
       "      <td>foto, raymond, rutting, volkskrant, amsterdam,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12544</th>\n",
       "      <td>eerst, toesprak, royal, verkiezingsoverwinn, d...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12545</th>\n",
       "      <td>jenny, zijdenamsterdam, woensdagvrijwel, hel, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12546</th>\n",
       "      <td>aantal, dagblad, per, huishoud, afgelop, derti...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12547</th>\n",
       "      <td>minister, borst, volksgezond, woensdag, duidel...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12548</th>\n",
       "      <td>controversiel, berlusconi, belangrijkst, bindm...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12549</th>\n",
       "      <td>roy, klopperd, helder, maandagd, konink, marin...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12550</th>\n",
       "      <td>new, york, verlies, ban, verenigd, stat, afgel...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12551</th>\n",
       "      <td>gerard, rev, james, joyc, lewis, carol, astrid...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12552</th>\n",
       "      <td>highlightjustitie, vond, onvoldo, bewijsvan, o...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12553</th>\n",
       "      <td>sao, paulo, 20, sept, oostenrijk, daviscupploe...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12554</th>\n",
       "      <td>consumentenprijz, nederland, april, jar, geste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12555</th>\n",
       "      <td>ottman, bakkal, rust, ingevall, schiet, psv, b...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12556</th>\n",
       "      <td>berlijn, vrouw, hitler, propagandaminister, jo...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12557</th>\n",
       "      <td>rabobank, verzet, enig, grot, bank, nederland,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12558</th>\n",
       "      <td>sted, verpleegkund, werk, naast, ban, ziekenhu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12559 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  topic\n",
       "0      wereld, zondagmorg, antropolog, dr, mattijs, p...     99\n",
       "1      samenvattingd, speurtocht, efraim, zuroff, naz...     16\n",
       "2      vol, verwacht, klopp, hartjes, onz, stoer, man...     16\n",
       "3      nieuwkomer, bedrijf, denkt, flink, salaris, ge...      5\n",
       "4      ziekenhuiz, hengelo, leeuward, vandag, gestaak...      3\n",
       "5      ajacied, klaasjan, huntelar, gisterocht, vrien...     99\n",
       "6      pol, gemeent, oswiecim, houdt, juli, referendu...     99\n",
       "7      politiek, lev, staatssecretaris, hof, vvd, zij...     20\n",
       "8      brit, over, ieder, pasgebor, baby, kraampresen...     20\n",
       "9      vermoed, zon, noordkoreaan, leider, kim, jongi...      9\n",
       "10     kop, gonzalez, geeft, columbian, red, vreugdet...     99\n",
       "11     open, ministerie, stelt, strafrecht, onderzoek...     12\n",
       "12     koningin, beatrix, hoogsteig, person, hangt, b...     99\n",
       "13     amerikan, ministerie, defensie, gister, all, m...     19\n",
       "14     rio, janeiro, noord, brazilie, boer, familie, ...     99\n",
       "15     busbedrijf, connexxion, koninginnedag, tijden,...     10\n",
       "16     samenvattingdor, mariek, ess, delft, dinsdag, ...     12\n",
       "17     hoofdrol, vertolk, nieuw, opera, international...     99\n",
       "18     war, haald, kabinet, inen, snel, 8, miljard, e...      1\n",
       "19     gestrand, bangkok, duikt, inen, sinterklas, aa...     20\n",
       "20     onz, correspondentwagen, maandagpopulair, maal...      4\n",
       "21     mens, vloer, won, 19deeeuw, da, costabuurt, am...     99\n",
       "22     amsterdam, aantal, vrouw, tijden, kort, bevall...      3\n",
       "23     elsbeth, etty, volgend, wek, vakantie, column,...     99\n",
       "24     kabinet, vannacht, akkoord, bereikt, begrot, 2...      1\n",
       "25     samenvattingdor, manno, den, berg, herman, sta...      1\n",
       "26     zit, sind, twee, dag, wer, thuis, etag, amster...     99\n",
       "27     minister, grav, defensie, gister, eind, kamerd...     20\n",
       "28     highlightcd, tweedor, jan, colijndoetinchem, z...     99\n",
       "29     nederland, spoorweg, gan, lon, inhoud, conduct...      5\n",
       "...                                                  ...    ...\n",
       "12529  uitzendconcern, randstad, gat, komend, wek, tw...      5\n",
       "12530  precies, period, abn, amro, eerst, ker, kwarta...     15\n",
       "12531  rotterdam, 20, sept, nieuw, hooglerar, moet, l...      5\n",
       "12532  kroonprin, willemalexander, maxima, trouw, 2, ...     20\n",
       "12533  samenvattingvan, onz, financiel, redactie, ams...      1\n",
       "12534  redacteur, amsterdam, zender, at5, voel, pietj...     99\n",
       "12535  secretarisgeneral, navo, georg, robertson, mac...     19\n",
       "12536  amerikan, president, bush, elk, versoepel, eco...     19\n",
       "12537  aardedonker, onderan, keldertrap, kijk, angsti...     19\n",
       "12538  samenvattingdor, bert, huisjes, amsterdam, don...     12\n",
       "12539  verenigd, stat, geconfronteerd, ernstigst, ene...      8\n",
       "12540  genetisch, gemanipuleerd, maissoort, starlink,...      7\n",
       "12541  kop, asielzoeker, verwijdercentrum, duik, vak,...      9\n",
       "12542  wit, kist, bedekt, wit, bloem, kaart, emotione...     12\n",
       "12543  foto, raymond, rutting, volkskrant, amsterdam,...     10\n",
       "12544  eerst, toesprak, royal, verkiezingsoverwinn, d...     20\n",
       "12545  jenny, zijdenamsterdam, woensdagvrijwel, hel, ...      3\n",
       "12546  aantal, dagblad, per, huishoud, afgelop, derti...     99\n",
       "12547  minister, borst, volksgezond, woensdag, duidel...      3\n",
       "12548  controversiel, berlusconi, belangrijkst, bindm...     19\n",
       "12549  roy, klopperd, helder, maandagd, konink, marin...     16\n",
       "12550  new, york, verlies, ban, verenigd, stat, afgel...      5\n",
       "12551  gerard, rev, james, joyc, lewis, carol, astrid...     99\n",
       "12552  highlightjustitie, vond, onvoldo, bewijsvan, o...     12\n",
       "12553  sao, paulo, 20, sept, oostenrijk, daviscupploe...     99\n",
       "12554  consumentenprijz, nederland, april, jar, geste...      1\n",
       "12555  ottman, bakkal, rust, ingevall, schiet, psv, b...     99\n",
       "12556  berlijn, vrouw, hitler, propagandaminister, jo...     99\n",
       "12557  rabobank, verzet, enig, grot, bank, nederland,...      1\n",
       "12558  sted, verpleegkund, werk, naast, ban, ziekenhu...      5\n",
       "\n",
       "[12559 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('/home/anne/tmpanne/AEM_data/dataset_burscher.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
